{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954999c0-e934-4f17-90eb-83287d60204b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "from ximg_to_ypdf_autoencoder import Ximg_to_Ypdf_Autoencoder\n",
    "from denoising_util import *\n",
    "# Get the directory of the currently running file\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the path to the utils directory relative to the current file's directory\n",
    "utils_dir = os.path.abspath(os.path.join(current_dir, '..', 'ml_backbone'))\n",
    "\n",
    "# Add the utils directory to the Python path\n",
    "sys.path.append(utils_dir)\n",
    "from utils import DataMilking_Nonfat, DataMilking\n",
    "from utils import CustomScheduler\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed39fc09-d138-4528-b87d-9d608b790de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset and Feed to Dataloader\n",
    "datapath = \"/Users/jhirschm/Documents/MRCO/Data_Changed/Test\"\n",
    "data = DataMilking_Nonfat(root_dir=datapath, pulse_number=2)\n",
    "# Calculate the lengths for each split\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = int(0.1 * len(data))\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "# Perform the split\n",
    "train_dataset, val_dataset, test_dataset = random_split(data, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6b2b01-29dc-49f4-83cb-bb74840da021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "encoder_layers = [\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "]\n",
    "\n",
    "decoder_layers = [\n",
    "    nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "    nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "    nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "]\n",
    "\n",
    "autoencoder = Ximg_to_Ypdf_Autoencoder(encoder_layers, decoder_layers)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0001)\n",
    "max_epochs = 20\n",
    "scheduler = CustomScheduler(optimizer, patience=3, early_stop_patience = 6, cooldown=2, lr_reduction_factor=0.5, max_num_epochs = max_epochs, improvement_percentage=0.01)\n",
    "model_save_dir = \"/Users/jhirschm/Documents/MRCO/Data_Changed/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330f7f31-1dc7-40fd-bc21-bb4d7790502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96663def-491b-4788-b5db-a163f1ed0e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Train Loss: 1.1065313834, Validation Loss: 0.9908687197\n",
      "\n",
      "\n",
      "Improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhirschm/Documents/MRCO/COOKIE_ML/src/ml_backbone/utils/custom_schedulers.py:42: UserWarning: Epoch parameter is deprecated and will be removed in a future release.\n",
      "  warnings.warn(\"Epoch parameter is deprecated and will be removed in a future release.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Train Loss: 0.9906093570, Validation Loss: 0.9904687668\n",
      "\n",
      "\n",
      "Epoch [3/20] - Train Loss: 0.9904603718, Validation Loss: 0.9904172077\n",
      "\n",
      "\n",
      "Epoch [4/20] - Train Loss: 0.9904311397, Validation Loss: 0.9904002478\n",
      "\n",
      "\n",
      "Epoch [5/20] - Train Loss: 0.9904194362, Validation Loss: 0.9903940169\n",
      "\n",
      "\n",
      "Epoch 5: reducing learning rate from 0.000100 to 0.000050\n",
      "Epoch [6/20] - Train Loss: 0.9904171628, Validation Loss: 0.9903934793\n",
      "\n",
      "\n",
      "Epoch [7/20] - Train Loss: 0.9904168568, Validation Loss: 0.9903932237\n",
      "\n",
      "\n",
      "Epoch [8/20] - Train Loss: 0.9904168226, Validation Loss: 0.9903930414\n",
      "\n",
      "\n",
      "Epoch [9/20] - Train Loss: 0.9904165047, Validation Loss: 0.9903929360\n",
      "\n",
      "\n",
      "Epoch 9: reducing learning rate from 0.000050 to 0.000025\n",
      "Epoch [10/20] - Train Loss: 0.9904163858, Validation Loss: 0.9903929050\n",
      "\n",
      "\n",
      "Epoch [11/20] - Train Loss: 0.9904166761, Validation Loss: 0.9903928855\n",
      "\n",
      "\n",
      "Epoch [12/20] - Train Loss: 0.9904168763, Validation Loss: 0.9903928592\n",
      "\n",
      "\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "identifier = \"testAutoencoder\"\n",
    "autoencoder.to(device)\n",
    "best_model, best_epoch, train_losses, val_losses, best_val_loss= autoencoder.train_model(train_dataloader, val_dataloader, criterion, optimizer, scheduler, model_save_dir, identifier, device, checkpoints_enabled=True, resume_from_checkpoint=False, max_epochs=max_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9481ee-4008-4a63-a914-7081f8c39108",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = os.path.join(model_save_dir, f\"{identifier}_results.txt\")\n",
    "with open(results_file, 'w') as f:\n",
    "    f.write(\"Model Training Results\\n\")\n",
    "    f.write(\"======================\\n\")\n",
    "    f.write(f\"Data Path: {datapath}\\n\")\n",
    "    f.write(f\"Model Save Directory: {model_save_dir}\\n\")\n",
    "    f.write(\"\\nModel Parameters and Hyperparameters\\n\")\n",
    "    f.write(\"-----------------------------------\\n\")\n",
    "    f.write(f\"Patience: {scheduler.patience}\\n\")\n",
    "    f.write(f\"Cooldown: {scheduler.cooldown}\\n\")\n",
    "    f.write(f\"Learning Rate Reduction Factor: {scheduler.lr_reduction_factor}\\n\")\n",
    "    f.write(f\"Improvement Percentage: {scheduler.improvement_percentage}\\n\")\n",
    "    f.write(f\"Initial Learning Rate: {optimizer.param_groups[0]['lr']}\\n\")\n",
    "    f.write(\"\\nModel Architecture\\n\")\n",
    "    f.write(\"------------------\\n\")\n",
    "    f.write(f\"Encoder Layers: {encoder_layers}\\n\")\n",
    "    f.write(f\"Decoder Layers: {decoder_layers}\\n\")\n",
    "    f.write(\"\\nAdditional Notes\\n\")\n",
    "    f.write(\"----------------\\n\")\n",
    "    f.write(\"First trial on S3DF for Denoising.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d5787-e132-4559-8e08-c731669f21a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6a5b7-faa8-437c-ad26-0009d8d2dd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
